Appendix A. GQM+Strategies Process Checklist
The following checklist provides guidance for applying GQM+Strategies. It aims at
easy comprehensibility and lists the logical steps to be performed. More detailed
descriptions of the activities in the GQM+Strategies process and the GQM+Strategies
concepts can be found by following the pointers (in parentheses) to the respective
sections in the book.
Initialize
Define purpose (Sect. 3.1)
Define scope (Sect. 3.2)
Describe the organizational structure (Sect. 3.2)
Get management commitment (Sects. 3.1 and 3.2)
Get personnel resources (Sect. 3.3)
Plan implementation (Sect. 3.3)
Motivate and train personnel for GQM+Strategies application (Sect. 3.4)
Characterize Environment
Comprehend and define the environment of the GQM+Strategies application
(Sect. 4.1)
Identify risks that might constrain the application of GQM+Strategies (Sect. 4.1)
Identify opportunities that might support the application of GQM+Strategies
(Sect. 4.1)
Define Goals and Strategies, and Measurement
Identify existing goals, strategies, and relevant assets (Sects. 5.1 and 5.2)
Select existing or identify new goals to start with (Sects. 5.3.1 and 5.3.2)
Provide rationales for the goals (Sects. 5.3.1 and 5.3.2)
Describe the goals in a structured way by using the organizational goal template
(Sect. 5.3.2)
Identify strategies that contribute to reaching the goals (Sect. 5.3.3)
Prioritize strategies and select the most promising ones (Sect. 5.3.3)
V. Basili et al., Aligning Organizations Through Measurement, The Fraunhofer IESE Series 187
on Software and Systems Engineering, DOI 10.1007/978-3-319-05047-8,
# Springer International Publishing Switzerland 2014
188
Appendix A. GQM+Strategies Process Checklist
Find and close gaps between goals and strategies (Sect. 5.3.3)
Define measures for measuring goal attainment (Sect. 5.3.5)
Define thresholds and potential explanations (i.e., interpretation models) for the
success or failure of each goal and related strategies (Sect. 5.3.5)
Iterate by refining goals and strategies until the scope is covered (Sects. 5.3.1-5.3.5)
Review and adjust goals and strategies (Sect. 5.4)
Plan Grid Implementation
Plan strategy deployment with stakeholders (Sect. 6.1)
Set up measurement, analysis, and reporting procedures (Sect. 6.2)
Organize training to prepare personnel with respect to strategy implementation
(Sect. 6.3)
Train personnel with respect to measurement, analysis, and reporting (Sect. 6.3)
Execute Plans
Analyze Outcomes
Execute strategies (Sect. 7.1)
Collect and analyze data (Sect. 7.2)
Monitor local strategy deployment (Sect. 7.2)
Adjust strategy implementation, if necessary (Sect. 7.3)
Adjust measurement, analysis, and reporting procedures, if necessary (Sect. 7.3)
Analyze overall strategy deployment and goal attainment (Sects. 8.1 and 8.2)
Gather feedback from relevant stakeholders (Sect. 8.3)
Analyze if the environment (i.e., the context) has changed (Sect. 8.3)
Question the strategies and the assumptions they are based on (Sect. 8.3)
Make proposals for improvement (Sect. 8.3)
Package Improvements
Change goals or strategies, if necessary (Sect. 9.1)
Communicate revised or new goals and strategies (Sect. 9.2)
Store relevant information and experience from the application of GQM+Strategies
for future use (Sect. 9.3)
Appendix B. GQM+Strategies Evaluation
Questionnaire
The goal of this survey is to evaluate the benefits of the GQM+Strategies
approach for your organization. This input will be used for improving the
method in future. All questions are phrased as statements you may agree with
or disagree with. There are no right or wrong answers. Your personal opinion
is what matters most. All data gathered here will be analyzed anonymously
and not be distributed to a third person so that no information about the
respondent will be disclosed under any circumstances.
Background Information
A1: What is the name of your company?
A2: What is your current position?
A3: For how many years have you been working in this position?
Training and Expertise in the GQM+Strategies Approach
B1: What GQM+Strategies training have you already obtained?
B1.1: Motivational talk or short (<1 day) presentation
B1.2: One-day method tutorial
B1.3: Two-day method tutorial
B1.4: Training for method trainers and promoters
B1.5: Other training (please specify):
How many times?
B2: For what purposes have you already used the GQM+Strategies approach? How many times?
B.2.1: I have employed the method in an industrial organization
B.2.2: I have given the motivational talk
B.2.3: I have given the 1-day method tutorial
B.2.4: I have given the 2-day method tutorial
(continued)
V. Basili et al., Aligning Organizations Through Measurement, The Fraunhofer IESE Series 189
on Software and Systems Engineering, DOI 10.1007/978-3-319-05047-8,
# Springer International Publishing Switzerland 2014
190
Appendix B. GQM+Strategies Evaluation Questionnaire
B2: For what purposes have you already used the GQM+Strategies approach? How many times?
B.2.5: I have given the training for method trainers and promoters
B.2.6: I have moderated the 1-day exercise workshop
B.2.7: I have moderated a real-world industrial workshop
B.2.8: Other purpose (please specify):
Assessment of the GQM+Strategies Approach
Strongly
disagree
1
Neither/
Disagree nor
Strongly I don't
Agree agree know
2
3
4
5
Alignment
C1.1: Using GQM+Strategies, I'm
able to harmonize goals, strategies,
and measurement data
C1.2: GQM+Strategies supports me
in tracking my goals and strategies
C1.3: Using GQM+Strategies, I'm
able to align my work activities
with the goals and strategies of
the organization
C1.4: GQM+Strategies supports me
in aligning goals and strategies across
organizational units
C1.5: Using GQM+Strategies, gaps
between goals, strategies, and
measurement data become obvious
C1.6: GQM+Strategies supports me
in closing gaps between goals,
strategies, and measurement data
C1.7: GQM+Strategies supports me
in identifying nonbeneficial goals,
strategies, and measurement data
Transparency
C2.1: GQM+Strategies supports
me in getting a clearer picture of
the goals and strategies of my
organization
C2.2: Using GQM+Strategies, the
goals and strategies of my
organization become more
transparent for me
Strongly Neither/
disagree Disagree nor
1
2
3
Agree
4
Strongly I don't
agree know
5
(continued)
Appendix B. GQM+Strategies Evaluation Questionnaire
191
Transparency
C2.3: GQM+Strategies supports
me in identifying contradictory
goals and strategies across different
organizational units
C2.4: Using GQM+Strategies helps
me in understanding the
relationships between goals and
strategies
C2.5: GQM+Strategies supports
me in understanding the rationale
for defined goals and strategies
C2.6: GQM+Strategies supports
me in getting a consistent
understanding of goals and
strategies across different
organizational units
C2.7: GQM+Strategies supports
me in communicating goals and
strategies across different
organizational units
Measurability
C3.1: GQM+Strategies helps me in
quantifying my organization's goals
and strategies
C3.2: Using GQM+Strategies supports
me in measuring the success/failure of
goals and strategies
C3.3: GQM+Strategies supports me in
collecting mandatory measurement
data
C3.4: GQM+Strategies supports me in
identifying superfluous measurement
data
C3.5: GQM+Strategies helps me in
optimizing the benefits from
collecting measurement data
C3.6: Using GQM+Strategies helps
me to identify unsuccessful strategies
C3.7: Using GQM+Strategies helps
me in assessing the attainment of
goals
Strongly
disagree
1
Neither/
Disagree nor
2 3
Agree
4
Strongly I don't
agree know
5 Strongly
disagree
1
Neither/
Disagree nor
2 3
Strongly
Agree agree
4 5
I don't
know
192
Appendix B. GQM+Strategies Evaluation Questionnaire
General Comments to the GQM+Strategies Approach
E1: What do you like about GQM+Strategies in particular?
E2: What don't you like about GQM+Strategies at all?
Final Evaluation of the GQM+Strategies Approach
F1: What school grade would you give to the GQM+Strategies approach?
A
Excellent
B
Good
C
Average
D
Low
F
Failed
I don't know
Thank you for participating in the survey!
Appendix C. Authors
Victor Basili
Victor Basili is Professor Emeritus of Computer Science at the University of
Maryland. He holds a PhD in Computer Science from the University of Texas, Austin
and is the recipient of two honorary degrees from the University of Sannio, Italy
(2004) and the University of Kaiserslautern, Germany (2005). He served as founding
director of the Fraunhofer Center for Experimental Software Engineering and the
Software Engineering Laboratory at NASA/GSFC. He has worked on measuring,
evaluating, and improving the software development process and product using
methods that include Iterative Enhancement (IE), the Goal-Question-Metric
Approach (GQM), the Quality Improvement Paradigm (QIP), and the Experience
Factory (EF). He has developed, tailored, evaluated, and evolved these techniques for
several organizations. He has been the recipient of grants from government agencies
and companies including NSF, NASA, AFOSR, ONR, AFOSR, AFRL, DARPA,
IBM, Hughes, NEC, Amdahl, Coopers and Lybrand, Ricoh, Mutsuhito Panasonic,
Daimler Benz, Bellcore, and Fujitsu. Dr. Basili is the recipient of several awards,
including the NASA Group Achievement Award (1996), ACM SIGSOFT Outstanding
Research Award (2000), IEEE Computer Society Harlan Mills Award (2003),
and the Fraunhofer Medal (2007). He has authored over 250 journals and refereed
conference papers and is Co-Editor-in-Chief of the Journal of Empirical Software
Engineering. He is an IEEE and ACM Fellow.
Jens Heidrich
Dr. Jens Heidrich is head of the Process Management division at the Fraunhofer
Institute for Experimental Software Engineering IESE in Kaiserslautern, Germany
and a lecturer at the University of Kaiserslautern, Germany. His research interests are
in the area of measurement-based improvement of processes in general, specifically
in the field of cost and effort estimation of development projects, assessment of
software product quality, and agile development practices. Prior to his current
position, he was the head of the Processes and Measurement department at IESE
where he was responsible for research and technology transfer projects. He graduated
V. Basili et al., Aligning Organizations Through Measurement, The Fraunhofer IESE Series 193
on Software and Systems Engineering, DOI 10.1007/978-3-319-05047-8,
# Springer International Publishing Switzerland 2014
194
Appendix C. Authors
from the University of Kaiserslautern, Germany, with a Diploma degree in Computer
Science (summa cum laude) and received his doctoral degree (Dr. rer. nat.) from the
same university (summa cum laude).
He has been teaching and training in both university and industry environments
since 2001 and is a member of the program committees of different national and
international conferences, such as the International Conference on Product Focused
Software Development and Process Improvement (PROFES) and the EUROMICRO
Conference on Software Engineering and Advanced Applications (SEAA). He is a
member of the German Informatics Society (Gesellschaft fu¨r Informatik e.V.) and
part of the managing committee of the section “Software Measurement.”
Martin Kowalczyk
Martin Kowalczyk is a researcher at Technische Universita¨t Darmstadt, Germany,
at the Department of Information Systems. His current research focuses on Business
Intelligence and Analytics in the context of organizational decision-making
processes.
Prior to his current position, Martin was a researcher and consultant at the
Fraunhofer Institute for Experimental Software Engineering IESE, where he was
a member of the Processes Management division. His research activities focused on
subjects concerning software development processes and goal-oriented measurement
approaches. In the context of industrial projects, he provided consultancy
services to several international organizations from the aerospace, finance, and
services domains on topics from the area of software process improvement and
measurement. He has led process improvement initiatives and has established
measurement programs for his customers.
Martin graduated from the University of Karlsruhe, Germany, with a Diploma
degree in Industrial Engineering. He is coauthor of one book and several international
peer-reviewed publications on topics related to software process management,
software-business alignment, and measurement.
Ju¨ rgen Mu¨ nch
Ju¨rgen Mu¨nch is a full professor in the Department of Computer Science at the
University of Helsinki, Finland, and head of its Software Systems Research Group.
His research centers on software measurement and quantitative analysis, process
and quality engineering, global software development, cloud-based software engineering,
and empirical software engineering. Mu¨nch has been a principal investigator
in numerous research and industrial development projects. Prior to his current
position, Mu¨nch was a division head at the Fraunhofer Institute for Experimental
Software Engineering IESE in Kaiserslautern, Germany, where he was responsible
for research and technology transfer in the area of software process and quality
engineering. He was also an executive board member of the temporary research
Appendix C. Authors
195
institute SFB 501 at the University of Kaiserslautern, Germany. Mu¨nch has been
awarded the Distinguished Professor Award FiDiPro (endowed with €1,900,000) of
Tekes, the IFIP TC2 Manfred Paul Award for Excellence in Software Theory and
Practice, several best paper awards, and the Technology Innovation Award sponsored
by the Rhineland-Palatinate Lotto Foundation. He has been the chair
of several renowned software engineering conferences such as the International
Conference on Software and Systems Process (ICSSP), and the ACM/IEEE
Symposium on Empirical Software Engineering and Measurement (ESEM). He is
Vice-Chairman of the German Association for Software Metrics and Cost Estimation
(DASMA).
Dieter Rombach
Prof. Dr. H. Dieter Rombach studied mathematics and computer science at the
University of Karlsruhe, Germany, and obtained his Ph.D. in Computer Science
from the University of Kaiserslautern, Germany in 1984. Since 1992, he has held
the Software Engineering Chair in the Department of Computer Science at the
University of Kaiserslautern. In addition, he is the founding and executive director
of the Fraunhofer Institute for Experimental Software Engineering IESE in
Kaiserslautern, Germany. He is the author of more than 200 scientific publications.
In 1990, he received the “Presidential Young Investigator Award” of the National
Science Foundation (NSF) in the USA. He has been awarded the Service Medal of
the State of Rhineland-Palatinate (2000); the Distinguished Postdoctoral Award of
the College for Computer, Mathematical, and Physical Sciences of the University
of Maryland (2003); the Federal Cross of Merit on Ribbon of the Federal Republic
of Germany (2009); an honorary doctorate degree by the University of Oulu,
Finland (2009); and the Fraunhofer Medal (2013). Since 2009, he has been the
chairman of the IEEE Awards Committees for the Software Process Achievement
Award (SPA) and for the Harlan Mills Award. Furthermore, he is coeditor of
several international journals (e.g., McCluwer Journal for Empirical Software
Engineering) and acts as a program committee member and chair of several
software engineering conferences. He is a member of the Gesellschaft fu¨r
Informatik (GI) and a Fellow of both the ACM (since 2010) and the IEEE Computer
Society (since 2003).
Carolyn Seaman
Dr. Seaman is an Associate Professor of Information Systems at the University of
Maryland Baltimore County (UMBC). Her research generally falls under the
umbrella of empirical studies of software engineering, with particular emphases
on maintenance, organizational structure, communication, measurement, COTSbased
development, and qualitative research methods. Dr. Seaman is also a
Research Fellow at the Fraunhofer Center for Experimental Software Engineering,
196
Appendix C. Authors
Maryland, where she participates in research on experience management in software
engineering organizations and software metrics. Her current research focuses
on the effective and efficient management of Technical Debt in software systems
under maintenance. She holds a PhD in Computer Science from the University of
Maryland, College Park, an MS in Information and Computer Science from
Georgia Tech, and a BA in Computer Science and Mathematics from the College
of Wooster (Ohio). She has worked in the software industry as a software engineer
and consultant and has conducted most of her research in industrial and governmental
settings (e.g., IBM Canada Ltd., NASA, Xerox).
Adam Trendowicz
Adam Trendowicz is a senior consultant at the Fraunhofer Institute for Experimental
Software Engineering IESE in Kaiserslautern, Germany, where he leads the
Measurement and Prediction team. He received his PhD in Computer Science from
the University of Kaiserslautern, Germany. Dr. Trendowicz has led multiple
measurement-based software improvement activities in software companies of
different sizes and from various domains (e.g., in Germany, France, Japan, and
India). He has been involved in functional software size estimation (Function Points
Analysis) and productivity benchmarking in organizations from both industry and
the public sector. Dr. Trendowicz has trained and coached IT/software strategic
alignment with measurement in both industrial and academic contexts. Last but not
least, he has led the development of measurement-based project governance
initiatives in the context of software development organizations. Dr. Trendowicz
has authored the book “Software Cost Estimation, Benchmarking, and Risk Assessment.
The Software Decision-Makers' Guide to Predictable Software Development.”
Moreover, he has coauthored more than 20 international journals and
conference publications. Dr. Trendowicz's other software engineering interests
include: (1) project management, (2) software product quality modeling and evaluation,
and (3) technology validation by means of empirical methods.
Bibliography
Accenture (2004) Managing IT investments in the high-performance business. Strategic information
technology effectiveness (SITE). Report, Accenture LLP
Ambler SW (1998) Process patterns: building large-scale systems using object technology.
Cambridge University Press, Cambridge, UK
Anto´n AI, McCracken WM, Potts C (1994) Goal decomposition and scenario analysis in business
process reengineering. In: Wijers G, Brinkkemper S, Wasserman T (eds) Advanced information
systems engineering. Springer, Berlin, pp 94-104
Basili VR (1981) Data collection, validation, and analysis. In: Tutorial on models and metrics for
software management and engineering, IEEE Catalog no. EHO-167-7, pp 310-313
Basili V (1985) Quantitative evaluation of software methodology, keynote address. In:
Proceedings of the first Pan Pacific computer conference, vol 1, pp 379-398
Basili VR (1989) Software development: a paradigm for the future. In: Presentation at the
thirteenth international computer software and applications conference, Los Alamitos, CA
Basili VR (1993) The experience factory and its relationship to other improvement paradigms. In:
Proceedings of the fourth European software engineering conference (ESEC), GarmischPartenkirchen,
Germany. The Proceedings appeared as Lecture Notes in Computer Science 717
Basili VR, Caldiera G (1995) Improve software quality by reusing knowledge and experience.
Sloan Manag Rev 37(1):55-64
Basili V, Green S (1994) Software process evolution at the SEL. IEEE Software 11(4):58-66
Basili VR, Rombach HD (1988) The TAME project: towards improvement-oriented software
environments. IEEE Trans Software Eng 14(6):758-773
Basili VR, Weiss DM (1984) A methodology for collecting valid software engineering data. IEEE
Trans Software Eng SE-10(6):728-738
Basili VR, Caldiera G, Rombach HD (1994a) The experience factory. In: Marciniak JJ
(ed) Encyclopedia of software engineering, vol 1, 2nd edn. Wiley, New York, pp 469-476
Basili VR, Caldiera G, Rombach HD (1994b) Goal question metric paradigm. In: Marciniak JJ
(ed) Encyclopedia of software engineering, vol 1, 2nd edn. Wiley, New York, pp 528-532
Basili V, Zelkowitz M, McGarry F, Page J, Waligora S, Pajerski R (1995) Special report: SEL's
software process-improvement program. IEEE Software 12(6):83-87
Basili VR, Green S, Laitenberger O, Shull F, Sørumga˚rd S, Zelkowitz MV (1996) The empirical
investigation of perspective-based reading. Empir Software Eng 13(12):1278-1296
Basili VR, Lindvall M, Regardie M, Seaman C, Heidrich J, Mu¨nch J, Rombach HD, Trendowicz A
(2010) Linking software development and business strategy through measurement. IEEE
Comput 43(4):57-65
Beck K, Andres C (2004) Extreme programming explained: embrace change. Addison-Wesley,
Boston, MA
Becker SA, Bostelman ML (1999) Aligning strategic and project measurement systems. IEEE
Software 16(3):46-51
Boehm B (2003) Value-based software engineering. ACM SIGSOFT Software Eng Notes
2(28):3-15
V. Basili et al., Aligning Organizations Through Measurement, The Fraunhofer IESE Series 197
on Software and Systems Engineering, DOI 10.1007/978-3-319-05047-8,
# Springer International Publishing Switzerland 2014
198
Bibliography
Briand LC, Differding CM, Rombach HD (1996) Practical guidelines for measurement-based
process improvement. Software Process Improv Pract 2(4):253-280
Brindgeland DM, Zahavi R (2008) Business modeling: a practical guide to realizing business
value. Morgan Kaufmann, Boston, MA
Budd CI, Budd CS (2009) A practical guide to earned value project management, 2nd edn.
Management Concepts, Vienna, VA
Buglione L, Abran A (2000) Balanced scorecards and GQM: what are the differences? In:
Proceedings to the third European software measurement conference, pp 18-20
Burlton R (2010) Delivering business strategy through process management. In: vom Brocke J,
Rosemann M (eds) Handbook on business process management 2. Springer, Berlin, pp 5-37
Chillarege R, Bhandari IS, Chaar JK, Halliday MJ, Moebus DS, Ray BK, Wong M-Y (1992)
Orthogonal defect classification - a concept for in-process measurements. IEEE Trans Software
Eng 18(11):943-956
Ciolkowski M, Laitenberger O, Rombach D, Shull F, Perry D (2002) Software inspections,
reviews and walkthroughs. In: Proceedings of the 24rd international conference on software
engineering, May 2002, pp 641-642
CMMI Product Team (2010) CMMI for development, version 1.3. Technical report
CMU/SEI-2010-TR-033, Software Engineering Institute, Carnegie Mellon University,
Pittsburgh, PA
Conradi R, Fuggetta A (2002) Improving software process improvement. IEEE Software
19(4):92-99
Damiani E, Mulazzani F, Russo B, Succi G (2008) SAF: strategic alignment framework for
monitoring organizations. In: Proceedings to the eleventh international conference on business
information systems, Innsbruck, Austria. Springer
Deming WE (1986) Out of the crisis. Massachusetts Institute of Technology, Center for Advance
Education Services, Cambridge, MA
Eckerson WW (2005) Performance dashboards: measuring, monitoring, and managing your
business. Wiley, Hoboken, NJ
Epstein M, Manzoni J-F (1998) Implementing corporate strategy: from Tableaux de Bord to
balanced scorecards. Eur Manag J 16(2):190-203
Fagan M (1976) Design and code inspections to reduce errors in program development. IBM Syst J
15(3):182-211
Gamma E, Helm R, Johnson R, Vlissides J (1994) Design patterns: Elements of Reusable ObjectOriented
Software. Addison-Wesley, Boston, MA
Gartner (2010) Gartner executive programs CIO survey. Press release, Gartner, Inc.
Gartner (2011) Forecast alert: IT spending, worldwide, 2008-2014, 4Q10 update. Press release,
Gartner, Inc.
Gresse C, Hoisl B, Wu¨ st J (1995) A process model for planning GQM-based measurement.
Technical report STTI-95-04-E, Software Technology Transfer Initiative, University of
Kaiserslautern
Hammer M (1990) Reengineering work: don't automate, obliterate. Harv Bus Rev 68(4):104-112
Hammer M (2010) What is business process management? In: vom Brocke J, Rosemann M (eds)
Handbook on business process management, vol 1. Springer, Heidelberg
Hammer M, Champy JA (1993) Reengineering the corporation: a manifesto for business revolution.
Harper, New York
Humphrey A (2005) SWOT analysis for management consulting. SRI Newsletter: History Corner,
SRI International, pp 7-8
ISO (2009) ISO/IEC 20926 - IFPUG functional size measurement method 2009, 2nd edn.
International Standardization Organization, Geneva
Kaplan RS, Norton DP (1992) The balanced scorecard: measures that drive performance. Harv
Bus Rev 70(1):71-79
Kaplan RS, Norton DP (1996) Balanced scorecard: translating strategy into action. Harvard
Business School Press, Boston, MA
Bibliography
199
Kaplan RS, Norton DP (2004) Strategy maps: converting intangible assets into tangible outcomes.
Harvard Business School Press, Boston, MA
Kaplan RS, Norton DP (2008) Execution premium: linking strategy to operations for competitive
advantage. Harvard Business School Press, Boston, MA
Kerth NL (2001) Project retrospectives: a handbook for team reviews. Dorset House, New York
Laitenberger O (2002) A survey of software inspection technologies. In: Chang SK (ed) Handbook
on software engineering and knowledge engineering. World Scientific, Singapore, pp 517-556
Mandic´ V (2012) Measurement-based value alignment and reasoning about organizational goals
and strategies: studied with ICT industry. Doctoral dissertation, University of Oulu, Finland
Mandic´ V, Basili V, Oivo M, Harjumaa L, Markkula J (2010a) Utilizing GQM+Strategies for an
organization-wide earned value analysis. In: Proceedings of the 36th EUROMICRO conference
on software engineering and advanced applications, 1-3 Sept 2010, pp 255-258
Mandic´ V, Oivo M, Rodr´ıguez P, Kuvaja P, Kaikkonen H, Turhan B (2010b) What is flowing in
lean software development? In: Proceedings of the first international conference on lean
enterprise software and systems, Helsinki, Finland, October 2010
Mandic´ V, Basili V, Harjumaa L, Oivo M, Markkula J (2010c) Utilizing GQM+Strategies for
business value analysis: an approach for evaluating business goals. In: Proceedings of the
fourth international symposium on empirical software engineering and measurement, BolzanoBozen,
Italy, pp 1-10
Mu¨ nch J, Heidrich J (2004) Software project control centers: concepts and approaches. J Syst
Software 70(1):3-19
Mu¨ nch J, Armbrust O, Kowalczyk M, Soto M (2012) Software process definition and management,
Fraunhofer IESE series on software and systems engineering. Springer, New York
Neely A, Gregory M, Platts K (1995) Performance measurement system design: a literature review
and research agenda. Int J Oper Prod Manag 15(4):80-116
Nudurupati SS, Bititci US, Kumar V, Chan FTS (2011) State of the art literature review on
performance measurement. Comput Ind Eng 60(2):279-290
Offen RJ, Jeffery R (1997) Establishing software measurement programs. IEEE Software
14(2):45-53
OGC (Office of Government Commerce) (2009) Managing successful projects with PRINCE2
2009 edition manual. The Stationery Office, UK
OMG (Object Management Group) (2010) The business motivation model (BMM) V. 1.1. Object
Management Group
PMI (2013) A guide to the project management body of knowledge (PMBOK guide), 5th edn.
Project Management Institute, Newtown Square, PA
Porter ME (1996) What is strategy? Harv Bus Rev 74(6):61-78
Porter ME (2008) The five competitive forces that shape strategy. Harv Bus Rev 86(1):78-93
Rombach HD, Verlage M (1995) Directions in software process research. In: Zelkowitz MV
(ed) Advances in computers, vol 41. Academic, Boston, MA
Rosemann M, vom Brocke J (2010) The six core elements of business process management. In:
vom Brocke J, Rosemann M (eds) Handbook on business process management, vol 1. Springer,
Heidelberg
Sarcia SA (2010) Is GQM+Strategies really applicable as is to non-software development
domains? In: Proceedings of the 2010 ACM-IEEE international symposium on empirical
software engineering and measurement, Bolzano-Bozen, Italy, pp 1-4
Schwaber K (2004) Agile project management with scrum. Microsoft Press, Redmond, WA
Selby RW (2005) Measurement-driven dashboards enable leading indicators for requirements and
design of large-scale systems. In: Proceedings of the 11th international software metrics
symposium, Como, Italy, 19-22 September, pp 1530-1435
Shewhart WA (1939) Statistical method from the viewpoint of quality control. The Graduate
School of the Department of Agriculture, Washington, DC. Reprinted by Dover Publications in
the Dover Books on Mathematics series in 1986
200
Bibliography
Trendowicz A, Heidrich J, Shintani K (2011) Aligning software projects with business objectives.
In: Proceedings of the joint conference of the 21th international workshop on software
measurement (IWSM) and the 6th international conference on software process and product
measurement (Mensura), Nara, Japan, 3-4 Nov 2011, vol I. IEEE Computer Society Press,
pp 142-150
van Solingen R, Berghout E (1999) Goal/question/metric method. McGraw-Hill, New York
The Fraunhofer Institute for Experimental
Software Engineering (IESE)
Fraunhofer IESE in Kaiserslautern is one of the worldwide leading research
institutes in the area of software and systems engineering. A major portion of the
products offered by its customers is defined by software. These products range from
automotive and transportation systems via automation and plant engineering, information
systems, healthcare and medical systems to software systems for the public
sector. The institute's software and systems engineering approaches are scalable,
which makes Fraunhofer IESE a competent technology partner for organizations of
any size-from small companies to major corporations.
Under the leadership of Prof. Dieter Rombach and Prof. Peter Liggesmeyer, the
contributions of Fraunhofer IESE have been a major boost to the emerging IT hub
Kaiserslautern for more than 15 years. In the Fraunhofer Information and Communication
Technology Group, the institute is cooperating with other Fraunhofer
institutes to develop trendsetting key technologies for the future.
Fraunhofer IESE is one of the 60 institutes of the Fraunhofer-Gesellschaft.
Together they have a major impact on shaping applied research in Europe and
contribute to Germany's competitiveness in international markets.
V. Basili et al., Aligning Organizations Through Measurement, The Fraunhofer IESE Series 201
on Software and Systems Engineering, DOI 10.1007/978-3-319-05047-8,
# Springer International Publishing Switzerland 2014
Index
A
Abstraction sheet, 41
baseline hypothesis, 41-42
impact on baseline hypothesis, 42
quality focus, 41
variation factors, 42
Alignment, 143
Analysis
qualitative, 110
quantitative, 110
Analyze outcomes phase, 107-125. See also
GQM+Strategies process
Assumption(s), 13, 26
B
Balanced Scorecard (BSC), 170
Bar chart, 97
Baseline hypothesis, 41. See also Abstraction
sheet
Box plot, 100
Business goals, 34
growth goals, 34
maintain goals, 34
specific focus goals, 34
success goals, 34
Business processes, 174. See also Business
Process Management
Business Process Management (BPM), 174
C
Case study, 181
Causality Theory, 183
Characterize environment phase, 25-28. See
also GQM+Strategies process
CMMI, 99
Constraints, 12. See also Organizational goal
Context, 13. See also GQM goal template
Context factor, 26. See also Context;
Environmental characteristic
Continuous improvement
cycle, 15
program, 15
D
Dashboard, 89
Data
aggregation, 73
analysis, 73, 108
collection (see Data collection)
interpretation, 73, 109
validation, 108
visualization, 74, 109
Data collection, 73. See also Measurement,
plan
automatic, 76
manual, 76
plan, 74
Defect slippage, 60
Define phase, 29-67. See also GQM+Strategies
process
Descriptive statistics, 96
E
Environment, 40. See also Context; GQM goal
template
Environmental characteristic, 28. See also
Context factor
Execute plans phase, 91-106. See also
GQM+Strategies process
Experience Factory (EF), 131
V. Basili et al., Aligning Organizations Through Measurement, The Fraunhofer IESE Series 203
on Software and Systems Engineering, DOI 10.1007/978-3-319-05047-8,
# Springer International Publishing Switzerland 2014
204
F
Feedback session, 111
Focus, 12, 39. See also GQM goal template;
Organizational goal
G
Goal
business, 33
GQM (see GQM goal)
GQM+Strategies (see GQM+Strategies,
goal)
organizational, 10 (see also
GQM+Strategies, goal)
Goal organizational, 11. See also
GQM+Strategies, goal
Goal-oriented measurement, 3. See also GQM
GQM
approach, 3
goal, 39 (see also GQM goal template)
goal template, 13
graphs, 69
metric, 14
question, 14
GQM goal template, 13
environment, 40
focus, 39-40
object, 39
purpose, 39
viewpoint, 39
GQM+Strategies
approach, 9
element, 11
goal, 38
goal template (see Organizational Goal
template)
grid, 15
improvement cycle, 17
model, 11
process, 14
GQM+Strategies grid, 15
GQM+Strategies process
analyze outcomes phase, 108
characterize environment phase, 26
define phase, 30
execute plans phase, 92
initialize phase, 20
package improvements phase, 128
plan grid implementation phase, 70
Grid. See GQM+Strategies grid
Growth goals, 33. See also Business goals
H
Histogram, 101
Index
I
Impact on baseline hypothesis, 42. See also
Abstraction sheet
Improvement, 16, 127. See also Plan-DoCheck-Act;
Quality Improvement
Paradigm
continuous, 127
cycle, 15
program, 91
Initialize phase, 19-24. See also
GQM+Strategies process
Interpretation model, 14. See also GQM,
graphs
horizontal, 80
vertical, 80
M
Magnitude, 11. See also Organizational goal
Maintain goals, 34. See also Business goal
Measure. See Metric
Measurement
data, 9
goal, 13 (see also GQM goal)
goal-oriented, 3 (see also GQM)
models, 11
objectives of, 13
plan, 69
processes, 73
program, 72
responsible, 75
Metric
base, 73
derived, 73
O
Object, 39. See also GQM goal template;
Organizational goal
Organizational goal, 11
constraints, 12
focus, 13
magnitude, 11
object, 13
organizational scope, 11
relationships, 12
template, 13
timeframe, 11
Organizational scope, 11. See also
Organizational goal
P
Package improvements phase, 127-140. See
also GQM+Strategies process
Index
Pie chart, 98
Plan-Do-Check-Act (PDCA), 17
Plan grid implementation phase, 69-90. See
also GQM+Strategies process
Process, 10
Project
management, 125
risks, 113
Purpose, 13. See also GQM goal template
Q
Quality assurance process, 76
Quality Assurance Team, 104
Quality focus, 41. See also Abstraction sheet
Quality Improvement Paradigm (QIP), 15
Quantitative evidence, 155
Questions, 14. See also GQM, question
R
Radar chart, 99
Relationships, 12. See also Organizational goal
Retrospectives, 111. See also Feedback session
Run chart, 98
205
S
Scatter plot, 100
Specific focus goals, 34. See also Business goal
Strategy, 12
alternative, 37
collaborative, 37
decisions, 37
execution, 93
plans, 69
Success goals, 34. See also Business goal
T
Template
GQM goal, 13
organizational goal, 13
Timeframe, 11. See also Organizational goal
V
Value-based software engineering (VBSE),
183
Variation factors, 42. See also Abstraction
sheet
Viewpoint, 39. See also GQM goal template